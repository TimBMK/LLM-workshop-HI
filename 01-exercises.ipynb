{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Embeddings: Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Model Training\n",
    "\n",
    "Train a custom Word2Vec Model. This time, use the full set of example sentences (rather than only the first 10). \n",
    "\n",
    "Think about whether or not you should set the tokens to lower case, and whether or not you should change the parameters of the Word2Vec algorithm (such as embedding dimensions and context window)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "full_docs = pd.read_csv('example_sentences.csv')['sentence'].tolist()\n",
    "\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Word Similarity\n",
    "\n",
    "a) Compute the cosine similarity between \"nlp\" and five words of your choosing. Note: the words must be present in the model!\n",
    "\n",
    "b) Get the 5 most similar words for \"nlp\" and another three words of your choosing. \n",
    "\n",
    "Hint: in order to access the similarity methods for your model, you need to navigate to the \"wv\" keyedvectors first, e.g. `word2vec_model.wv.similarity()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Visualization\n",
    "\n",
    "Load the `word2vec-google-news-300` model we used before, and visualize the embeddings. Since we the new model will have more tokens, it will improve visual clarity to only plot a subset of words. You can pick whichever words you choose, but you will find a suggestion below.\n",
    "\n",
    "Before visualizing, you will need to reduce the dimensions of the embeddings. Try both the PCA algorithm (as before) and the T-SNE algorithm. What do you notice in the visualization?\n",
    "\n",
    "Hint: Depending on the number of words you choose, you may need to adjust the \"perplexity\" parameter of the T- SNE algorithm to something smaller than your number of words.\n",
    "    \n",
    "More info on the T-SNE algorithm here: https://scikit-learn.org/stable/modules/manifold.html#t-sne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"NLP\", \"sentiment\", \"analysis\", \"physics\", \"scientist\", \n",
    "         \"man\", \"woman\", \"doctor\", \"nurse\", \"research\", \"medicine\",\n",
    "         \"engineering\", \"technology\", \"AI\", \"machine\", \"learning\",\n",
    "         \"data\", \"big\", \"small\", \"fast\", \"slow\", \"good\", \"bad\",\n",
    "         \"up\", \"down\", \"left\", \"right\", \"positive\", \"negative\",\n",
    "         \"productivity\", \"efficiency\", \"accuracy\", \"precision\",]\n",
    "\n",
    "perplexity = len(words)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim.downloader as api\n",
    "\n",
    "word2vec = api.load('...')\n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Model Bias\n",
    "\n",
    "Think about words that may carry a certain bias in specific domains. Find term pairs (like \"men\" and \"women\" for gendered biases) and get the cosine similarity for each word of a specific domain (e.g. \"nurse\", \"doctor\", etc.). How could you analyse these differences in your own research?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "### Other Models\n",
    "\n",
    "Load another model from the ones available in *Gensim*. Are the same biases present?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all available models\n",
    "for model_name in list(api.info()['models'].keys()):\n",
    "  print(model_name)\n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analogies\n",
    "\n",
    "Find more analogy tasks to run on the google-news-300 model. Is the model good at finding these? What does that say about the model? How does the task compare on other models?\n",
    "\n",
    "Hint: The `most_similar` method is capable of solving analogy tasks with the `negative` and `positive` arguments. Remeber that the syntax is `X2 - X1 + Y1 = Y2`. It may help to write out your analogy and formalize it before filling in the function arguments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
