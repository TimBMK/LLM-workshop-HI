{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents & Tools - Exercises\n",
    "\n",
    "Feel free to pick only one or several of these exercises - depending on whether you have your own data to work with and which aspects interest you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a RAG system with your own data\n",
    "\n",
    "If you have your own data, you can set up a RAG system yourself. You can use the workflows provided in the script. Feel free to use a different embedding model than Nomic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a different retrieval technique\n",
    "\n",
    "Apart from the similarity search we previously employed, the Chroma vector store we are using also supports Maximum Marginal Relevance (MMR) search. Do some research on MMR. What does it do differently than similarity search? \n",
    "\n",
    "Then, set up the same system as before, but change `search_type` argument of the retriever to `\"mmr\"`. You should also set the additional `search_kwargs` `\"fetch_k\"` and `\"lambda_mult\"` to configure the MMR search. \n",
    "\n",
    "How do results differ from the similarity search?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use different LLMs in your RAG system\n",
    "\n",
    "Use Ollama to use different models than GPT 4o-mini. Can you find a model that is good at deciding whether or not to use the retriever tool, and one that is good at generating text from the documents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a Wikipedia Retriever\n",
    "\n",
    "As mentioned, a retriever does not have to connect to a local vector store database. It can also connect to an API such as the Wikipedia API, which allows us to retrieve Wikipedia articles. \n",
    "\n",
    "Luckily, the LangChain community already set up a retriever function for the API endpoint. Use it to build a RAG system that utilizes wikipedia articles!\n",
    "\n",
    "_Hint_: The documents returned by the wikipedia retriever contain a \"summary\" field. Maybe this will be enough to pass to your model - rather than a full article?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever\n",
    " \n",
    "article_retriever = WikipediaRetriever(doc_content_chars_max=1000, # setting this very high means we will retrieve the full article. Watch the context window size of your model if passing them full!\n",
    "                                       top_k_results=10) # this sets the number of articles to retrieve\n",
    "\n",
    "\n",
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other use cases for agentic systems\n",
    "\n",
    "Come up with some use cases for agentic systems with or without tools. Could you use them in your research? What would the components be? Try your hand at building such a system!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
